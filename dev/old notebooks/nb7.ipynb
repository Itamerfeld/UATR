{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24233df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "from scipy.signal import find_peaks, butter, filtfilt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9913334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 128000 Hz\n",
      "Data shape: (10240000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/d9dsxkl92nz9mr2x53ct_fvh0000gn/T/ipykernel_17489/2284093387.py:2: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  fs, data = wavfile.read(data_file)\n"
     ]
    }
   ],
   "source": [
    "data_file = \"../data/scooter_example_1.wav\"\n",
    "fs, data = wavfile.read(data_file)\n",
    "\n",
    "# crop data\n",
    "start_time = 80 # seconds\n",
    "end_time = 160 # seconds\n",
    "data = data[int(start_time*fs):int(end_time*fs)]\n",
    "\n",
    "# data_file = \"../data/12062025_example.wav\"\n",
    "# fs, data = wavfile.read(data_file)\n",
    "\n",
    "\n",
    "# set time annotations\n",
    "# 1st detection: 3-37 seconds\n",
    "# 2nd detection: 91-143 seconds\n",
    "# need to account for time cropping\n",
    "time_annotations = np.zeros_like(data, dtype=int)\n",
    "# time_annotations[int(3*fs):int(37*fs)] = 1\n",
    "time_annotations[int(11*fs):int(63*fs)] = 1\n",
    "\n",
    "\n",
    "print(f\"Sample rate: {fs} Hz\")\n",
    "print(f\"Data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7279b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram parameters\n",
    "nperseg=16384  # 1024, 2048, 4096, 8192, 16384, 32768, 64768\n",
    "hop=0.25\n",
    "noverlap=int(nperseg * (1 - hop))\n",
    "window='hann'\n",
    "title='Spectrogram'\n",
    "colorscale='Viridis'\n",
    "crop_freq=None  # Set to None to disable cropping\n",
    "\n",
    "# # Compute spectrogram\n",
    "# frequencies, times, Sxx = signal.spectrogram(data, fs=fs, window=window, nperseg=nperseg, noverlap=noverlap)\n",
    "\n",
    "# # Crop frequencies if specified\n",
    "# if crop_freq is not None:\n",
    "#     freq_mask = frequencies <= crop_freq\n",
    "#     frequencies = frequencies[freq_mask]\n",
    "#     Sxx = Sxx[freq_mask, :]\n",
    "\n",
    "# # Convert to dB scale\n",
    "# Sxx_db = 10 * np.log10(Sxx + 1e-10)  # Add small value to avoid log(0)\n",
    "# # Sxx_db = np.clip(Sxx_db, a_min=-50, a_max=50)\n",
    "\n",
    "# # Create the heatmap\n",
    "# fig = go.Figure(data=go.Heatmap(z=Sxx_db, x=times, y=frequencies, colorscale=colorscale, colorbar=dict(title='Power (dB)')))\n",
    "\n",
    "# # Update layout\n",
    "# fig.update_layout(title=title, xaxis_title='Time (s)', yaxis_title='Frequency (Hz)', width=800, height=600)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5bb08c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afbc8417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total slices: 159\n",
      "Positive slices: 105\n",
      "Negative slices: 54\n"
     ]
    }
   ],
   "source": [
    "# preprocess into slices\n",
    "slice_length_seconds = 1  # seconds\n",
    "slice_length_samples = slice_length_seconds * fs\n",
    "slice_hop = 0.5  # seconds\n",
    "step = int(slice_hop * fs)\n",
    "num_of_slices = (len(data) - slice_length_samples) // step + 1\n",
    "data_slices = np.empty((num_of_slices, slice_length_samples))\n",
    "slice_annotations = []\n",
    "annotation_threshold = 0.25  # fraction of slice that must be annotated to label the slice as positive\n",
    "\n",
    "for start in range(0, len(data) - slice_length_samples + 1, step):\n",
    "    end = start + slice_length_samples\n",
    "    _data = data[start:end]\n",
    "    _annotation = 1 if np.mean(time_annotations[start:end]) >= annotation_threshold else 0\n",
    "    slice_annotations.append(_annotation)\n",
    "    data_slices[start // step, :] = _data\n",
    "\n",
    "slice_annotations = np.array(slice_annotations)\n",
    "# print some stats\n",
    "print(f\"Total slices: {len(data_slices)}\")\n",
    "print(f\"Positive slices: {np.sum(slice_annotations)}\")\n",
    "print(f\"Negative slices: {len(data_slices) - np.sum(slice_annotations)}\")\n",
    "\n",
    "with open(\"../data/processed_data/slices.pkl\", \"wb\") as f:\n",
    "    pickle.dump((data_slices, slice_annotations), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dc4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_graph_features(slice, fs=fs, nperseg=8192, noverlap=2048, window='hann', with_prints=False):\n",
    "    if with_prints:\n",
    "        print(\"Starting spectral graph feature computation...\")\n",
    "\n",
    "    _time = time.time()\n",
    "    # spectrogram\n",
    "    frequencies, times, Sxx = signal.spectrogram(slice, fs=fs, window=window, nperseg=nperseg, noverlap=noverlap)\n",
    "\n",
    "    if with_prints:\n",
    "        print(f\" ---------------------- Spectrogram computation time: {time.time() - _time:.3f} seconds\")\n",
    "    _time = time.time()\n",
    "\n",
    "    # convert to dB scale\n",
    "    Sxx_db = 10 * np.log10(Sxx + 1e-10)  # Add small value to avoid log(0)\n",
    "    if with_prints:\n",
    "        print(f\" ---------------------- dB conversion time: {time.time() - _time:.3f} seconds\")\n",
    "    _time = time.time()\n",
    "\n",
    "    # high-pass filter\n",
    "    cutoff_freq = 10  # Hz\n",
    "    b, a = butter(4, cutoff_freq / (0.5 * fs), btype='high')\n",
    "    Sxx = filtfilt(b, a, Sxx, axis=0)\n",
    "\n",
    "    if with_prints:\n",
    "        print(f\" ---------------------- High-pass filter time: {time.time() - _time:.3f} seconds\")\n",
    "    _time = time.time()\n",
    "\n",
    "    # compute correlation matrix\n",
    "    corr_matrix = np.corrcoef(Sxx)\n",
    "    if with_prints:\n",
    "        print(f\" ---------------------- Correlation matrix computation time: {time.time() - _time:.3f} seconds\")\n",
    "    _time = time.time()\n",
    "\n",
    "    # compute adjacency matrix\n",
    "    threshold = np.percentile(corr_matrix, 25)  # keep top 25% correlations\n",
    "    adj_matrix = (corr_matrix <= threshold).astype(int)\n",
    "    np.fill_diagonal(adj_matrix, 0)  # remove self-loops\n",
    "    if with_prints:\n",
    "        print(f\" ---------------------- Adjacency matrix computation time: {time.time() - _time:.3f} seconds\")\n",
    "    _time = time.time()\n",
    "\n",
    "    # create graph from adjacency matrix\n",
    "    G = nx.from_numpy_array(adj_matrix)\n",
    "    if with_prints:\n",
    "        print(f\" ---------------------- Graph creation time: {time.time() - _time:.3f} seconds\")\n",
    "    _time = time.time()\n",
    "\n",
    "    # compute Laplacian matrix\n",
    "    L = nx.laplacian_matrix(G).toarray()\n",
    "    if with_prints:\n",
    "        print(f\" ---------------------- Laplacian matrix computation time: {time.time() - _time:.3f} seconds\")\n",
    "    _time = time.time()\n",
    "\n",
    "    # compute eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(L)\n",
    "    if with_prints:\n",
    "        print(f\" ---------------------- Eigen decomposition time: {time.time() - _time:.3f} seconds\")\n",
    "\n",
    "    return eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5da013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing features for all slices...\n",
      "Computed features for slice 2/159\n",
      "Computed features for slice 3/159\n",
      "Computed features for slice 4/159\n",
      "Computed features for slice 5/159\n",
      "Computed features for slice 6/159\n",
      "Computed features for slice 7/159\n",
      "Computed features for slice 8/159\n",
      "Computed features for slice 9/159\n",
      "Computed features for slice 10/159\n",
      "Computed features for slice 11/159\n",
      "Computed features for slice 12/159\n",
      "Computed features for slice 13/159\n",
      "Computed features for slice 14/159\n",
      "Computed features for slice 15/159\n",
      "Computed features for slice 16/159\n",
      "Computed features for slice 17/159\n",
      "Computed features for slice 18/159\n",
      "Computed features for slice 19/159\n",
      "Computed features for slice 20/159\n",
      "Computed features for slice 21/159\n",
      "Computed features for slice 22/159\n",
      "Computed features for slice 23/159\n",
      "Computed features for slice 24/159\n",
      "Computed features for slice 25/159\n",
      "Computed features for slice 26/159\n",
      "Computed features for slice 27/159\n",
      "Computed features for slice 28/159\n",
      "Computed features for slice 29/159\n",
      "Computed features for slice 30/159\n",
      "Computed features for slice 31/159\n",
      "Computed features for slice 32/159\n",
      "Computed features for slice 33/159\n",
      "Computed features for slice 34/159\n",
      "Computed features for slice 35/159\n",
      "Computed features for slice 36/159\n",
      "Computed features for slice 37/159\n",
      "Computed features for slice 38/159\n",
      "Computed features for slice 39/159\n",
      "Computed features for slice 40/159\n",
      "Computed features for slice 41/159\n",
      "Computed features for slice 42/159\n",
      "Computed features for slice 43/159\n",
      "Computed features for slice 44/159\n",
      "Computed features for slice 45/159\n",
      "Computed features for slice 46/159\n",
      "Computed features for slice 47/159\n",
      "Computed features for slice 48/159\n",
      "Computed features for slice 49/159\n",
      "Computed features for slice 50/159\n",
      "Computed features for slice 51/159\n",
      "Computed features for slice 52/159\n",
      "Computed features for slice 53/159\n",
      "Computed features for slice 54/159\n",
      "Computed features for slice 55/159\n",
      "Computed features for slice 56/159\n",
      "Computed features for slice 57/159\n",
      "Computed features for slice 58/159\n",
      "Computed features for slice 59/159\n",
      "Computed features for slice 60/159\n",
      "Computed features for slice 61/159\n",
      "Computed features for slice 62/159\n",
      "Computed features for slice 63/159\n",
      "Computed features for slice 64/159\n",
      "Computed features for slice 65/159\n",
      "Computed features for slice 66/159\n",
      "Computed features for slice 67/159\n",
      "Computed features for slice 68/159\n",
      "Computed features for slice 69/159\n",
      "Computed features for slice 70/159\n",
      "Computed features for slice 71/159\n",
      "Computed features for slice 72/159\n",
      "Computed features for slice 73/159\n",
      "Computed features for slice 74/159\n",
      "Computed features for slice 75/159\n",
      "Computed features for slice 76/159\n",
      "Computed features for slice 77/159\n",
      "Computed features for slice 78/159\n",
      "Computed features for slice 79/159\n",
      "Computed features for slice 80/159\n",
      "Computed features for slice 81/159\n",
      "Computed features for slice 82/159\n",
      "Computed features for slice 83/159\n",
      "Computed features for slice 84/159\n",
      "Computed features for slice 85/159\n",
      "Computed features for slice 86/159\n",
      "Computed features for slice 87/159\n",
      "Computed features for slice 88/159\n",
      "Computed features for slice 89/159\n",
      "Computed features for slice 90/159\n",
      "Computed features for slice 91/159\n",
      "Computed features for slice 92/159\n",
      "Computed features for slice 93/159\n",
      "Computed features for slice 94/159\n",
      "Computed features for slice 95/159\n",
      "Computed features for slice 96/159\n",
      "Computed features for slice 97/159\n",
      "Computed features for slice 98/159\n",
      "Computed features for slice 99/159\n",
      "Computed features for slice 100/159\n",
      "Computed features for slice 101/159\n",
      "Computed features for slice 102/159\n",
      "Computed features for slice 103/159\n",
      "Computed features for slice 104/159\n",
      "Computed features for slice 105/159\n",
      "Computed features for slice 106/159\n",
      "Computed features for slice 107/159\n",
      "Computed features for slice 108/159\n",
      "Computed features for slice 109/159\n",
      "Computed features for slice 110/159\n",
      "Computed features for slice 111/159\n",
      "Computed features for slice 112/159\n",
      "Computed features for slice 113/159\n",
      "Computed features for slice 114/159\n",
      "Computed features for slice 115/159\n",
      "Computed features for slice 116/159\n",
      "Computed features for slice 117/159\n",
      "Computed features for slice 118/159\n",
      "Computed features for slice 119/159\n",
      "Computed features for slice 120/159\n",
      "Computed features for slice 121/159\n",
      "Computed features for slice 122/159\n",
      "Computed features for slice 123/159\n",
      "Computed features for slice 124/159\n",
      "Computed features for slice 125/159\n",
      "Computed features for slice 126/159\n",
      "Computed features for slice 127/159\n",
      "Computed features for slice 128/159\n",
      "Computed features for slice 129/159\n",
      "Computed features for slice 130/159\n",
      "Computed features for slice 131/159\n",
      "Computed features for slice 132/159\n",
      "Computed features for slice 133/159\n",
      "Computed features for slice 134/159\n",
      "Computed features for slice 135/159\n",
      "Computed features for slice 136/159\n",
      "Computed features for slice 137/159\n",
      "Computed features for slice 138/159\n",
      "Computed features for slice 139/159\n",
      "Computed features for slice 140/159\n",
      "Computed features for slice 141/159\n",
      "Computed features for slice 142/159\n",
      "Computed features for slice 143/159\n",
      "Computed features for slice 144/159\n",
      "Computed features for slice 145/159\n",
      "Computed features for slice 146/159\n",
      "Computed features for slice 147/159\n",
      "Computed features for slice 148/159\n",
      "Computed features for slice 149/159\n",
      "Computed features for slice 150/159\n",
      "Computed features for slice 151/159\n",
      "Computed features for slice 152/159\n",
      "Computed features for slice 153/159\n",
      "Computed features for slice 154/159\n",
      "Computed features for slice 155/159\n",
      "Computed features for slice 156/159\n",
      "Computed features for slice 157/159\n",
      "Computed features for slice 158/159\n",
      "Computed features for slice 159/159\n",
      "Computed features for slice 160/159\n"
     ]
    }
   ],
   "source": [
    "# # compute features for all slices\n",
    "# features = []\n",
    "# print(\"Computing features for all slices...\")\n",
    "# for slice in data_slices:\n",
    "#     _features = compute_spectral_graph_features(slice, with_prints=False)\n",
    "\n",
    "#     _file_name = f\"../data/processed_data/features_slice_{len(features)+1}.pkl\"\n",
    "#     with open(_file_name, \"wb\") as f:\n",
    "#         pickle.dump(_features, f)\n",
    "\n",
    "#     features.append(_features)\n",
    "#     print(f\"Computed features for slice {len(features)+1}/{len(data_slices)}\")\n",
    "    \n",
    "# with open(\"../data/processed_data/slices_and_features.pkl\", \"wb\") as f:\n",
    "#     pickle.dump((data_slices, slice_annotations, features), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8db0d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
